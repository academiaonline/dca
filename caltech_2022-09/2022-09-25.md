# Experimenting with Docker bridge networks
1. List the networks:

    ```
    sudo docker network ls
    ```
2. Inspect the networks in order to obtain the IP addresses:

    ```
    sudo docker inspect bridge
    
    sudo docker inspect my_bridge
    ```
1. We need to use IP adresses when communicating containers in the default bridge:

    ```
    sudo docker exec test1 ping -c 1 172.17.0.3
    ```
1. We can use Docker internal DNS resolution when connecting containers in the custom bridge:

    ```
    sudo docker exec custom1 ping -c 1 custom2
    ```
1. We can connect one container to many networks. Let us connect the test container to the custom bridge:

    ```
    sudo docker network connect my_bridge test1
    ```
1. We can use internal DNS resolution for any container in the custom bridge:

    ```
    sudo docker exec custom1 ping -c 1 test1
    ```
1. Bridges are isolated by IPtables firewall:

    ```
    sudo iptables -S -t filter | grep A.DOCKER-ISOLATION-STAGE-2.*DROP
    ```
# Experimenting with the Host network:
1. List the network interface configuration of the host machine:

    ```
    ifconfig
    ```
3. Create a container connected to the Host network:

    ```
    sudo docker run --detach --name host1 --network host --tty busybox
    ```
1. List the network interface configuration from inside the container. It will be the same configuration as the host machine because the container is connected to the Host network:

    ```
    sudo docker exec host1 ifconfig
    ```
# Experimenting with the Null network:
1. Create a container using the null network:

    ```
    sudo docker run --detach --name none1 --network none --tty busybox
    ```
1. When we create a container attached to the null network there is no network interface defined inside the container:

    ```
    sudo docker exec none1 ifconfig
    ```
1. You can still send or retrieve files from the isolated container using `cp` and `exec`:

    ```
    sudo docker cp examples.desktop none1:/tmp/
    
    sudo docker exec none1 ls /tmp/
    ```
# Sample application written in Python
1. Create a folder for the project:

    ```
    mkdir --parents ${HOME}/anagrams/
    ```
1. Download the Python script for our application:

    ```   
    wget https://raw.githubusercontent.com/sebastian-colomar/anagrams/docker/src/anagrams.py --output-document ${HOME}/anagrams/anagrams.py
    ```
3. Download a sample dictionary:

    ```
    wget https://raw.githubusercontent.com/sebastian-colomar/anagrams/docker/data/words.txt --output-document ${HOME}/anagrams/words.txt
    ```
1. Run the Python script that will analyze the data in the sample dictionary showing the number of Anagrams:

    * https://en.wikipedia.org/wiki/Anagram

    ```
    cd ${HOME}/anagrams/
    
    python3 anagrams.py
    ```
# How to deploy our Python sample application using Docker Compose
1. Create a Docker Compose file to describe the services we want to run:

    ```
    tee ${HOME}/anagrams/docker-compose.yaml 0<<EOF

    services:
      anagrams:
        command:
        - python3
        - script.py
        image: index.docker.io/library/python:alpine
        restart: "no"
        user: nobody:nogroup
        volumes:
        - ./anagrams.py:/app/script.py:ro
        - ./words.txt:/app/words.txt:ro
        working_dir: /app/
    version: "2.0"
    
    EOF
    ```
1. Install Docker Compose in your host machine:

    ```
    sudo apt-get install -y docker-compose
    ```
1. Deploy the composite application using Docker Compose:

    ```
    cd ${HOME}/anagrams/
    
    sudo docker-compose up
    ```
1. Docker compose will be equivalent to running the following Docker command:

    ```
    sudo docker run --restart no --user nobody:nogroup --volume ${HOME}/anagrams/anagrams.py:/app/script.py:ro --volume ${HOME}/anagrams/words.txt:/app/words.txt:ro --workdir /app/ index.docker.io/library/python:alpine python3 script.py
    ```
# Example of Continuous Integration using Github Actions:
1. https://github.com/sebastian-colomar/anagrams
2. https://github.com/sebastian-colomar/anagrams/blob/main/.github/workflows/ci.yaml

# Docker Swarm
Docker Compose provides orchestration of our Docker services but does not provide high availability. 
In case of failure of the host machine it is not capable of migrating the workload to another host.
For the purpose of high availability and automatic failover, we need to enable Docker Swarm.

1. Initialize Docker Swarm mode in your master host machine:

    ```
    sudo docker swarm init --advertise-addr $( hostname -i )
    ```
1. Check the members of the created cluster:

    ```
    sudo docker node ls
    ```
# Deploy the PHP sample application using Docker Swarm
1. Create a Docker Compose file for this deployment using Docker Swarm (Docker Compose version 3):

    ```
    tee ${HOME}/phpinfo/docker-swarm.yaml 0<<EOF

    configs:
      phpinfo-config:
        external: false
        file: index.php
    services:
      phpinfo:
        command:
          - php
          - -f
          - index.php
          - -S
          - 0.0.0.0:8080
        configs:
          - source: phpinfo-config
            target: /data/index.php
            uid: '65534'
            gid: '65534'
            mode: 0400
        deploy:
          replicas: 3
        image: index.docker.io/library/php:alpine
        ports:
          - 9090:8080
        user: nobody:nogroup
        working_dir: /data/
    version: '3.8'

    EOF    
    ```
1. A more complete version of the previous template:
    ```
    tee ${HOME}/phpinfo/docker-swarm-full.yaml 0<<EOF

    configs:
        phpinfo-config:
            external: false
            file: ./index.php
    networks:
        phpinfo-network:
            driver: overlay
            internal: true
    services:
        phpinfo:
            command:
                -   -f
                -   index.php
                -   -S
                -   0.0.0.0:8080
            configs:
                -   source: phpinfo-config
                    target: /data/index.php
                    uid: '65534'
                    gid: '65534'
                    mode: 0400
            deploy:
                placement:
                    constraints:
                        -   node.role == worker
                resources:
                    limits:
                        cpus: '0.1'
                        memory: 100M
                    reservations:
                        cpus: '0.1'
                        memory: 100M
            entrypoint:
                -   php
            environment:
                -   AUTHOR=Sebastian
            expose:
                -   8080
            healthcheck:
                interval: 30s
                retries: 3
                start_period: 10s
                test:
                    -   CMD
                    -   curl
                    -   localhost:8080/index.php
                    -   -f
                timeout: 30s
            image: index.docker.io/library/php:alpine@sha256:ab23b416d86aec450ee7b75727f6bbec272edc2764a1b6fad13bc2823c59bb6b
            labels:
                app: phpinfo
            networks:
                -   phpinfo-network
            ports:
                -   8080
            read_only: true
            user: nobody:nogroup
            working_dir: /data/
    version: '3.8'

    EOF    
    ```
1. Create a Docker Compose file to deploy the PHP application using Docker Compose version 2:

    ```
    tee ${HOME}/phpinfo/docker-compose.yaml 0<<EOF

    services:
      phpinfo:
        command:
          - php
          - -f
          - index.php
          - -S
          - 0.0.0.0:8080
        image: index.docker.io/library/php:alpine
        ports:
          - 9010:8080
        scale: 3
        user: nobody:nogroup
        volumes:
        - ./index.php:/data/index.php:ro
        working_dir: /data/
    version: '2.0'

    EOF    
    ```
    
